name: Overlay and Split Datasets
description: Overlays labels on inputs and splits into positive/negative datasets with user-defined batch size.

inputs:
  - {name: train_dataset, type: Dataset}
  - {name: test_dataset, type: Dataset}

outputs:
  - {name: positive_train_dataset, type: Dataset}
  - {name: negative_train_dataset, type: Dataset}
  - {name: positive_test_dataset, type: Dataset}
  - {name: negative_test_dataset, type: Dataset}

implementation:
  container:
    image: python:3.8
    command:
      - sh
      - -c
      - |
        python3 -m pip install --quiet tensorflow numpy
        exec python3 -u - "$@"
      - |
        import tensorflow as tf
        import numpy as np
        import argparse
        import random

        parser = argparse.ArgumentParser()
        parser.add_argument('--train_dataset', required=True)
        parser.add_argument('--test_dataset', required=True)
        parser.add_argument('--positive_train_dataset', required=True)
        parser.add_argument('--negative_train_dataset', required=True)
        parser.add_argument('--positive_test_dataset', required=True)
        parser.add_argument('--negative_test_dataset', required=True)
        parser.add_argument('--batch_size', type=int, default=60000)
        args = parser.parse_args()

        def overlay_y_on_x(X_sample, y_sample):
            max_sample = tf.reduce_max(X_sample, axis=0, keepdims=True)
            X_zeros = tf.zeros([10], dtype=tf.float32)
            updates = tf.tensor_scatter_nd_update(
                X_zeros, indices=[[y_sample]], updates=tf.reshape(max_sample, [-1])
            )
            X_sample = tf.tensor_scatter_nd_update(X_sample, indices=[[0]], updates=updates)
            return X_sample, y_sample

        def re_overlay(X_sample, new_label):
            max_sample = tf.reduce_max(X_sample, axis=0, keepdims=True)
            X_zeros = tf.zeros([10], dtype=tf.float32)
            updates = tf.tensor_scatter_nd_update(
                X_zeros, indices=[[new_label]], updates=tf.reshape(max_sample, [-1])
            )
            X_sample = tf.tensor_scatter_nd_update(X_sample, indices=[[0]], updates=updates)
            return X_sample, new_label

        def generate_negative(label):
            choices = list(range(10))
            choices.remove(label.numpy())
            return random.choice(choices)

        def process_dataset(ds, batch_size):
            pos_ds = []
            neg_ds = []

            for x, y in ds.unbatch():
                # Overlay positive
                x_pos, y_pos = overlay_y_on_x(x, y)
                pos_ds.append((x_pos, y_pos))

                # Generate negative
                wrong_label = tf.py_function(generate_negative, [y], tf.int32)
                x_neg, y_neg = re_overlay(x, wrong_label)
                neg_ds.append((x_neg, y_neg))

            pos_ds = tf.data.Dataset.from_tensor_slices(pos_ds).batch(batch_size)
            neg_ds = tf.data.Dataset.from_tensor_slices(neg_ds).batch(batch_size)
            return pos_ds, neg_ds

        # Load datasets
        train_ds = tf.data.experimental.load(args.train_dataset)
        test_ds = tf.data.experimental.load(args.test_dataset)

        # Process
        pos_train, neg_train = process_dataset(train_ds, args.batch_size)
        pos_test, neg_test = process_dataset(test_ds, args.batch_size)

        # Save
        tf.data.experimental.save(pos_train, args.positive_train_dataset)
        tf.data.experimental.save(neg_train, args.negative_train_dataset)
        tf.data.experimental.save(pos_test, args.positive_test_dataset)
        tf.data.experimental.save(neg_test, args.negative_test_dataset)

        print(f"Done: batch_size={args.batch_size}")

    args:
      - --train_dataset
      - {inputPath: train_dataset}
      - --test_dataset
      - {inputPath: test_dataset}
      - --positive_train_dataset
      - {outputPath: positive_train_dataset}
      - --negative_train_dataset
      - {outputPath: negative_train_dataset}
      - --positive_test_dataset
      - {outputPath: positive_test_dataset}
      - --negative_test_dataset
      - {outputPath: negative_test_dataset}
      - --batch_size
      - {value: 60000}  # default, can be set in GUI
