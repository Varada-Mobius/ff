<<<<<<< HEAD
name: Overlay and Split Datasets
description: Overlays labels on inputs and splits into positive/negative datasets with user-defined batch size.

inputs:
<<<<<<< HEAD
=======
  - {name: x_train, type: Dataset}
  - {name: y_train, type: Dataset}
  - {name: x_test, type: Dataset}
  - {name: y_test, type: Dataset}
  - {name: batch_size, type: string}   

outputs:
  - {name: x_train, type: Dataset}
  - {name: x_test, type: Dataset}
  - {name: y_train, type: Dataset}
  - {name: y_test, type: Dataset}
>>>>>>> 60d32831c78040da7a039a772a4f55c08bbd1be5
  - {name: train_dataset, type: Dataset}
  - {name: test_dataset, type: Dataset}
=======
name: Overlay and Split Positive and Negative Datasets
description: Overlays labels and splits the datasets into positive and negative datasets by label corruption.

inputs:
  - {name: overlaid_train_dataset, type: Dataset}
  - {name: overlaid_test_dataset, type: Dataset}
  - {name: batch_size, type: Integer}

outputs:
  - {name: positive_train_dataset, type: Dataset}
  - {name: negative_train_dataset, type: Dataset}
  - {name: positive_test_dataset, type: Dataset}
  - {name: negative_test_dataset, type: Dataset}


>>>>>>> 71fc28f0a52d0a9786641b4d18d11000e52c212d

outputs:
  - {name: positive_train_dataset, type: Dataset}
  - {name: negative_train_dataset, type: Dataset}
  - {name: positive_test_dataset, type: Dataset}
  - {name: negative_test_dataset, type: Dataset}

implementation:
  container:
    image: python:3.8
    command:
      - sh
      - -c
      - |
        python3 -m pip install --quiet tensorflow numpy
        exec python3 -u - "$@"
      - |
        import tensorflow as tf
        import numpy as np
        import argparse
        import random

        parser = argparse.ArgumentParser()
<<<<<<< HEAD
        parser.add_argument('--train_dataset', required=True)
        parser.add_argument('--test_dataset', required=True)
=======
        parser.add_argument('--overlaid_train_dataset', required=True)
        parser.add_argument('--overlaid_test_dataset', required=True)
>>>>>>> 71fc28f0a52d0a9786641b4d18d11000e52c212d
        parser.add_argument('--positive_train_dataset', required=True)
        parser.add_argument('--negative_train_dataset', required=True)
        parser.add_argument('--positive_test_dataset', required=True)
        parser.add_argument('--negative_test_dataset', required=True)
<<<<<<< HEAD
        parser.add_argument('--batch_size', type=int, default=60000)
        args = parser.parse_args()

        def overlay_y_on_x(X_sample, y_sample):
            max_sample = tf.reduce_max(X_sample, axis=0, keepdims=True)
            X_zeros = tf.zeros([10], dtype=tf.float32)
            updates = tf.tensor_scatter_nd_update(
                X_zeros, indices=[[y_sample]], updates=tf.reshape(max_sample, [-1])
            )
            X_sample = tf.tensor_scatter_nd_update(X_sample, indices=[[0]], updates=updates)
            return X_sample, y_sample
=======
        parser.add_argument('--batch_size', type=int, required=False, default=60000)
        args = parser.parse_args()

        batch_size = args.batch_size
>>>>>>> 71fc28f0a52d0a9786641b4d18d11000e52c212d

        def re_overlay(X_sample, new_label):
            max_sample = tf.reduce_max(X_sample, axis=0, keepdims=True)
            X_zeros = tf.zeros([10], dtype=tf.float32)
            updates = tf.tensor_scatter_nd_update(
                X_zeros, indices=[[new_label]], updates=tf.reshape(max_sample, [-1])
            )
            X_sample = tf.tensor_scatter_nd_update(X_sample, indices=[[0]], updates=updates)
            return X_sample, new_label

        def generate_negative(label):
            choices = list(range(10))
            choices.remove(label.numpy())
            return random.choice(choices)

<<<<<<< HEAD
        def process_dataset(ds, batch_size):
=======
        def split_dataset(ds, batch_size):
>>>>>>> 71fc28f0a52d0a9786641b4d18d11000e52c212d
            pos_ds = []
            neg_ds = []

            for x, y in ds.unbatch():
<<<<<<< HEAD
                # Overlay positive
                x_pos, y_pos = overlay_y_on_x(x, y)
                pos_ds.append((x_pos, y_pos))

                # Generate negative
=======
                pos_ds.append((x, y))

>>>>>>> 71fc28f0a52d0a9786641b4d18d11000e52c212d
                wrong_label = tf.py_function(generate_negative, [y], tf.int32)
                x_neg, y_neg = re_overlay(x, wrong_label)
                neg_ds.append((x_neg, y_neg))

            pos_ds = tf.data.Dataset.from_tensor_slices(pos_ds).batch(batch_size)
            neg_ds = tf.data.Dataset.from_tensor_slices(neg_ds).batch(batch_size)
            return pos_ds, neg_ds

<<<<<<< HEAD
        # Load datasets
        train_ds = tf.data.experimental.load(args.train_dataset)
        test_ds = tf.data.experimental.load(args.test_dataset)

        # Process
        pos_train, neg_train = process_dataset(train_ds, args.batch_size)
        pos_test, neg_test = process_dataset(test_ds, args.batch_size)

        # Save
=======
        train_ds = tf.data.experimental.load(args.overlaid_train_dataset)
        test_ds = tf.data.experimental.load(args.overlaid_test_dataset)

        pos_train, neg_train = split_dataset(train_ds, args.batch_size)
        pos_test, neg_test = split_dataset(test_ds, args.batch_size)

>>>>>>> 71fc28f0a52d0a9786641b4d18d11000e52c212d
        tf.data.experimental.save(pos_train, args.positive_train_dataset)
        tf.data.experimental.save(neg_train, args.negative_train_dataset)
        tf.data.experimental.save(pos_test, args.positive_test_dataset)
        tf.data.experimental.save(neg_test, args.negative_test_dataset)
<<<<<<< HEAD

        print(f"Done: batch_size={args.batch_size}")

    args:
      - --train_dataset
      - {inputPath: train_dataset}
      - --test_dataset
      - {inputPath: test_dataset}
      - --positive_train_dataset
      - {outputPath: positive_train_dataset}
      - --negative_train_dataset
      - {outputPath: negative_train_dataset}
      - --positive_test_dataset
      - {outputPath: positive_test_dataset}
      - --negative_test_dataset
      - {outputPath: negative_test_dataset}
      - --batch_size
      - {value: 60000}  # default, can be set in GUI
=======

    args:
      - --overlaid_train_dataset
      - {inputPath: overlaid_train_dataset}
      - --overlaid_test_dataset
      - {inputPath: overlaid_test_dataset}
      - --batch_size
      - {inputValue: batch_size}
      - --positive_train_dataset
      - {outputPath: positive_train_dataset}
      - --negative_train_dataset
      - {outputPath: negative_train_dataset}
      - --positive_test_dataset
      - {outputPath: positive_test_dataset}
      - --negative_test_dataset
      - {outputPath: negative_test_dataset}
      
>>>>>>> 71fc28f0a52d0a9786641b4d18d11000e52c212d
