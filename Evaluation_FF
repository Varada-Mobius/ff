name: Evaluate FFN Model for FF
description: Loads the trained FFN model and evaluates its accuracy on the test dataset.
inputs:
  - {name: trained_model, type: Model}
  - {name: test_dataset, type: Dataset}
outputs:
  - {name: accuracy, type: Float}
implementation:
  container:
    image: python:3.9
    command:
      - sh
      - -c
      - |
        PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet tensorflow keras || \
        PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet tensorflow keras --user
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse
        import pickle
        import os
        import tensorflow as tf
        import keras
        from keras import ops
        import zipfile
        import json

        class FFDense(keras.layers.Layer):
            def __init__(self, units, init_optimizer, loss_metric, num_epochs=50,
                         use_bias=True, kernel_initializer="glorot_uniform",
                         bias_initializer="zeros", kernel_regularizer=None,
                         bias_regularizer=None, **kwargs):
                super().__init__(**kwargs)
                self.dense = keras.layers.Dense(
                                                units,
                                                activation=None,  # or explicitly specify if needed
                                                use_bias=use_bias,
                                                kernel_initializer=kernel_initializer,
                                                bias_initializer=bias_initializer,
                                                kernel_regularizer=kernel_regularizer,
                                                bias_regularizer=bias_regularizer
                                                )
                self.relu = keras.layers.ReLU()
                self.optimizer = init_optimizer()
                self.loss_metric = loss_metric
                self.threshold = 1.5
                self.num_epochs = num_epochs

            def call(self, x):
                x_norm = ops.norm(x, ord=2, axis=1, keepdims=True) + 1e-4
                x_dir = x / x_norm
                res = self.dense(x_dir)
                return self.relu(res)

        class FFNetwork(keras.Model):
            def __init__(self, dims, **kwargs):
                super().__init__(**kwargs)
                self.layer_list = [keras.Input(shape=(dims[0],))]
                for d in range(len(dims) - 1):
                    self.layer_list.append(
                        FFDense(dims[d + 1])
                    )

            @tf.function(reduce_retracing=True)
            def overlay_y_on_x(self, data):
                X_sample, y_sample = data
                max_sample = ops.cast(ops.amax(X_sample, axis=0, keepdims=True), dtype="float64")
                X_zeros = ops.zeros([10], dtype="float64")
                X_update = tf.compiler.xla.dynamic_update_slice(X_zeros, max_sample, [y_sample])
                X_sample = tf.compiler.xla.dynamic_update_slice(X_sample, X_update, [0])
                return X_sample, y_sample

            @tf.function(reduce_retracing=True)
            def predict_one_sample(self, x):
                goodness_per_label = []
                x = ops.reshape(x, [ops.shape(x)[0] * ops.shape(x)[1]])
                for label in range(10):
                    h, _ = self.overlay_y_on_x((x, label))
                    h = ops.reshape(h, [-1, ops.shape(h)[0]])
                    goodness = []
                    for layer in self.layer_list[1:]:
                        h = layer(h)
                        goodness.append(ops.mean(ops.power(h, 2), 1))
                    goodness_per_label.append(ops.expand_dims(ops.sum(goodness, keepdims=True), 1))
                return ops.cast(ops.argmax(tf.concat(goodness_per_label, 1), 1), dtype="float64")

            def predict(self, data):
                return ops.vectorized_map(self.predict_one_sample, data).numpy().astype(int)

        parser = argparse.ArgumentParser()
        parser.add_argument('--trained_model', type=str, required=True)
        parser.add_argument('--test_dataset', type=str, required=True)
        parser.add_argument('--accuracy', type=str, required=True)
        args = parser.parse_args()

        # Extract model
        zip_path = args.trained_model
        extract_path = "/tmp/trained_model_extracted"

        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(extract_path)

        # List what was extracted
        print("Extracted model folder contains:", os.listdir(extract_path))

        # Check config.json content
        config_path = os.path.join(extract_path, "config.json")

        if os.path.exists(config_path):
          with open(config_path, "r") as f:
            model_json = f.read()
          print("config.json content:", model_json)
          model_config = json.loads(model_json)
          dims = model_config.get("dims")
          print("Loaded dims:", dims)
        else:
          print("ERROR: config.json not found in model zip!")
          dims = None

        if dims is None:
          raise ValueError("Cannot load model â€” dims not found in config.json!")

        
        model = FFNetwork(dims)
        model.build(input_shape=(None, dims[0]))
        model.load_weights(os.path.join(extract_path, "model.weights.h5"))

        # Load test dataset
        test_data = tf.data.experimental.load(args.test_dataset)

        # Run prediction and compute accuracy
        y_true = []
        y_pred = []

        for x_batch, y_batch in test_data:
            preds = model.predict(x_batch)
            y_true.extend(y_batch.numpy().tolist())
            y_pred.extend(preds.tolist())

        y_true = tf.convert_to_tensor(y_true)
        y_pred = tf.convert_to_tensor(y_pred)

        acc = tf.reduce_mean(tf.cast(tf.equal(y_true, y_pred), tf.float32)).numpy()

        # Save accuracy
        os.makedirs(os.path.dirname(args.accuracy), exist_ok=True)
        with open(args.accuracy, "w") as f:
            f.write(str(acc))
    args:
      - --trained_model
      - {inputPath: trained_model}
      - --test_dataset
      - {inputPath: test_dataset}
      - --accuracy
      - {outputPath: accuracy}
